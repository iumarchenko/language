{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë–µ—Ä–µ–º –æ—Ç—ã–∑—ã–≤—ã –∑–∞ –ª–µ—Ç–æ (–∏–∑ –∞—Ä—Ö–∏–≤–∞ —Å –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏ –∏–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–Ω—è—Ç–∏—è)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. –£—á–∏–º conv —Å–µ—Ç—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ - –≤—ã–±–∏—Ç—å auc –≤—ã—à–µ 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping  \n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\marchenko-\n",
      "[nltk_data]     i-u\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_excel(\"–æ—Ç–∑—ã–≤—ã –∑–∞ –ª–µ—Ç–æ.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>–í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ –≤—Å–µ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>–°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å—ë —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º üëçüëçüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>–£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ —á–µ—Ç–∫–æ. –í –æ—Ç–ª–∏—á–∏–∏ –æ—Ç –±–∞–Ω–∫–æ–º...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å –≤—Å–µ —Ö–æ—Ä–æ—à–æüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date\n",
       "0       5                                     It just works!  2017-08-14\n",
       "1       4  –í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è...  2017-08-14\n",
       "2       5                                        –û—Ç–ª–∏—á–Ω–æ –≤—Å–µ  2017-08-14\n",
       "3       5  –°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ ...  2017-08-14\n",
       "4       5                     –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.  2017-08-14\n",
       "5       5                                –í—Å—ë —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º üëçüëçüëç  2017-08-14\n",
       "6       5                          –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.  2017-08-14\n",
       "7       5                                     –í—Å–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç  2017-08-14\n",
       "8       5  –£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ —á–µ—Ç–∫–æ. –í –æ—Ç–ª–∏—á–∏–∏ –æ—Ç –±–∞–Ω–∫–æ–º...  2017-08-14\n",
       "9       5                                  –û—á–µ–Ω—å –≤—Å–µ —Ö–æ—Ä–æ—à–æüëç  2017-08-14"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20659, 3)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.loc[:4131]\n",
    "df_val = df.loc[4132:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4132, 3), (16527, 3))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 200\n",
    "max_len = 40\n",
    "\n",
    "# Training\n",
    "epochs = 20\n",
    "batch_size = 512\n",
    "print_batch_n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marchenko-i-u\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\marchenko-i-u\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    \n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    txt = [word for word in txt if len(word)>1]\n",
    "    \n",
    "    txt = [word for word in txt if word.isalnum()]\n",
    "    \n",
    "    return \" \".join(txt)\n",
    "\n",
    "df_train['Content'] = df_train['Content'].apply(preprocess_text)\n",
    "df_val['Content'] = df_val['Content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        it just works\n",
       "1    —Ü–µ–ª–æ–µ —É–¥–æ–±–Ω–æ–Ω–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–∏–∑ –º–∏–Ω—É—Å –±–æ–ª—å—à–æ–π –¥–æ—Å—Ç...\n",
       "2                                              –æ—Ç–ª–∏—á–Ω–æ\n",
       "3    –∑–∞–≤–∏—Å–∞—Ç—å —Ä–∞–±–æ—Ç–∞ –∞–Ω—Ç–∏–≤–∏—Ä—É—Å —Ä–∞–Ω–µ–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –Ω...\n",
       "4                               —É–¥–æ–±–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –±—ã—Å—Ç—Ä–æ\n",
       "5                                         —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º–∞\n",
       "6                                   —É–¥–æ–±–Ω—ã–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ\n",
       "7                                           —É—Å—Ç—Ä–∞–∏–≤–∞—Ç—å\n",
       "8    —Ä–∞–±–æ—Ç–∞—Ç—å —á—ë—Ç–∫–æ –æ—Ç–ª–∏—á–∏–µ –±–∞–Ω–∫–æ–º–∞—Ç –≤–µ—á–Ω–æ –∑–∞–≤–∏—Å–∞—Ç—å...\n",
       "9                                                     \n",
       "Name: Content, dtype: object"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Content'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = \" \".join(df_train[\"Content\"])\n",
    "train_corpus = train_corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_filtered = [word for word in tokens if word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = FreqDist(tokens_filtered)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    padding = [0]*(maxlen-len(result))\n",
    "    return padding + result[-maxlen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray([text_to_sequence(text, max_len) for text in df_train[\"Content\"]], dtype=np.int32)\n",
    "x_val = np.asarray([text_to_sequence(text, max_len) for text in df_val[\"Content\"]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ..., 105,  93,  12],\n",
       "       [  0,   0,   0, ...,   0,   0,   5],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   4,   1],\n",
       "       [  0,   0,   0, ...,   0,   0,   4]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 2, 3, 1], dtype=int64)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Rating\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "y_train = keras.utils.to_categorical(df_train[\"Rating\"], num_classes)\n",
    "y_val = keras.utils.to_categorical(df_val[\"Rating\"], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics='AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/8 [======>.......................] - ETA: 0s - loss: 1.7592 - auc: 0.7765WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.117165). Check your callbacks.\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 1.6735 - auc: 0.8265 - val_loss: 1.5266 - val_auc: 0.8318\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.3690 - auc: 0.8478 - val_loss: 1.2102 - val_auc: 0.8386\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.0458 - auc: 0.8551 - val_loss: 1.0944 - val_auc: 0.8463\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.9722 - auc: 0.8788 - val_loss: 1.0742 - val_auc: 0.9068\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 0.9150 - auc: 0.9076 - val_loss: 0.9697 - val_auc: 0.9182\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.8671 - auc: 0.9275 - val_loss: 0.9264 - val_auc: 0.9256\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.8271 - auc: 0.9359 - val_loss: 0.8875 - val_auc: 0.9363\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.7784 - auc: 0.9471 - val_loss: 0.8461 - val_auc: 0.9443\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.7347 - auc: 0.9525 - val_loss: 0.8045 - val_auc: 0.9449\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.7015 - auc: 0.9532 - val_loss: 0.7771 - val_auc: 0.9433\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.6761 - auc: 0.9540 - val_loss: 0.7553 - val_auc: 0.9441\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.6525 - auc: 0.9563 - val_loss: 0.7400 - val_auc: 0.9446\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.6312 - auc: 0.9587 - val_loss: 0.7233 - val_auc: 0.9465\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 0.6155 - auc: 0.9612 - val_loss: 0.7180 - val_auc: 0.9477\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 0.6036 - auc: 0.9629 - val_loss: 0.7054 - val_auc: 0.9491\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 1s 109ms/step - loss: 0.5918 - auc: 0.9646 - val_loss: 0.6963 - val_auc: 0.9506\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.5811 - auc: 0.9657 - val_loss: 0.6958 - val_auc: 0.9505\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 0.5702 - auc: 0.9670 - val_loss: 0.6884 - val_auc: 0.9511\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 0.5602 - auc: 0.9682 - val_loss: 0.6945 - val_auc: 0.9509\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.5502 - auc: 0.9690 - val_loss: 0.6893 - val_auc: 0.9511\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='auc', mode=\"auto\")  \n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 33ms/step - loss: 0.7317 - auc: 0.9450\n",
      "\n",
      "\n",
      "Test score: 0.7316719889640808\n",
      "Test accuracy: 0.9449595212936401\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_val, y_val, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. –ü—Ä–µ–¥–æ–±—É—á–∞–µ–º word2vec –∏ –µ–≥–æ —ç–º–±–µ–¥–∏–Ω–≥–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Ç–∫—É, –∫–∞–∫ –≤–ª–∏—è–µ—Ç –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelW2V = Word2Vec(sentences=df_train['Content'].apply(str.split), size=40, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_idf = TfidfVectorizer()\n",
    "vect_idf.fit_transform(df_train['Content'])\n",
    "tfidf = dict(zip(vect_idf.get_feature_names(), vect_idf.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vect_mean(txt):\n",
    "    vector_w2v = np.zeros(40)\n",
    "    n_w2v = 0\n",
    "    for wrd in txt.split():\n",
    "        if wrd in modelW2V:\n",
    "            vector_w2v += modelW2V[wrd]\n",
    "            n_w2v += 1\n",
    "    if n_w2v > 0:\n",
    "        vector_w2v = vector_w2v / n_w2v\n",
    "    return vector_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marchenko-i-u\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fee591cda204ccaa07c8e26f1b9f853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4132.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marchenko-i-u\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \"\"\"\n",
      "C:\\Users\\marchenko-i-u\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marchenko-i-u\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4d1a2f9ee341168c65ece085899f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=16527.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "arr_vect = []\n",
    "for txt in tqdm_notebook(df_train['Content']):\n",
    "    arr_vect.append(get_vect_mean(txt))\n",
    "    \n",
    "arr_vect_valid = []\n",
    "for txt in tqdm_notebook(df_val['Content']):\n",
    "    arr_vect_valid.append(get_vect_mean(txt))\n",
    "    \n",
    "train_w2v = np.asarray(arr_vect)    \n",
    "valid_w2v = np.asarray(arr_vect_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics='AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 1.7648 - auc: 0.7552WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.192580). Check your callbacks.\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 1.7093 - auc: 0.7795 - val_loss: 1.6187 - val_auc: 0.7290\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 1.5363 - auc: 0.7878 - val_loss: 1.4569 - val_auc: 0.7290\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 1.3633 - auc: 0.8015 - val_loss: 1.3525 - val_auc: 0.8604\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 1.2433 - auc: 0.8784 - val_loss: 1.2462 - val_auc: 0.8512\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 1.1062 - auc: 0.8747 - val_loss: 1.1512 - val_auc: 0.8512\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 1.0182 - auc: 0.8705 - val_loss: 1.1214 - val_auc: 0.8309\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.9795 - auc: 0.8725 - val_loss: 1.1024 - val_auc: 0.8493\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.9557 - auc: 0.8745 - val_loss: 1.0686 - val_auc: 0.8493\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 0.9354 - auc: 0.8784 - val_loss: 1.0415 - val_auc: 0.8594\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.9221 - auc: 0.8824 - val_loss: 1.0270 - val_auc: 0.8594\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.9120 - auc: 0.8835 - val_loss: 1.0171 - val_auc: 0.8681\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.9057 - auc: 0.8911 - val_loss: 1.0085 - val_auc: 0.8768\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.9011 - auc: 0.8928 - val_loss: 1.0020 - val_auc: 0.8768\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.8985 - auc: 0.8930 - val_loss: 0.9965 - val_auc: 0.8860\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.8964 - auc: 0.8948 - val_loss: 0.9931 - val_auc: 0.8860\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.8955 - auc: 0.8958 - val_loss: 0.9917 - val_auc: 0.8860\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.8953 - auc: 0.8952 - val_loss: 0.9886 - val_auc: 0.8860\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.8951 - auc: 0.8960 - val_loss: 0.9874 - val_auc: 0.8860\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 0.8956 - auc: 0.8950 - val_loss: 0.9896 - val_auc: 0.8860\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.8947 - auc: 0.8957 - val_loss: 0.9877 - val_auc: 0.8860\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(train_w2v, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 36ms/step - loss: 1.0087 - auc: 0.8760\n",
      "\n",
      "\n",
      "Test score: 1.0086997747421265\n",
      "Test accuracy: 0.8759726285934448\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(valid_w2v, y_val, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
